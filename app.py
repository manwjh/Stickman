"""
Flask åº”ç”¨ä¸»ç¨‹åº - AI ç«æŸ´äººæ•…äº‹åŠ¨ç”»ç”Ÿæˆå™¨

æä¾› RESTful API æ¥å£ï¼Œæ¥æ”¶ç”¨æˆ·æ•…äº‹æè¿°ï¼Œ
é€šè¿‡ LLM ç”Ÿæˆç«æŸ´äººåŠ¨ç”»æ•°æ®ã€‚

ä¸»è¦ç«¯ç‚¹:
- GET  /              - Web ç•Œé¢
- POST /api/generate - ç”ŸæˆåŠ¨ç”»
- GET  /api/health   - å¥åº·æ£€æŸ¥

Author: Your Name
License: MIT
"""
import os
import sys
import json
import logging
from flask import Flask, render_template, request, jsonify
from flask_cors import CORS

# é¦–å…ˆåŠ è½½é…ç½®åˆ°ç¯å¢ƒå˜é‡
from backend.config_loader import load_config_to_env

try:
    config_loader = load_config_to_env('config.yml', 'llm_config.yml')
except FileNotFoundError as e:
    print("=" * 60)
    print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
    print("=" * 60)
    print()
    print(str(e))
    print()
    print("è¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤:")
    print("1. ç¡®ä¿ config.yml å­˜åœ¨ï¼ˆç³»ç»Ÿé…ç½®ï¼‰")
    print("2. å¤åˆ¶ LLM ä»¤ç‰Œé…ç½®:")
    print("   cp llm_config.example.yml llm_config.yml")
    print("3. ç¼–è¾‘ llm_config.yml æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„APIå¯†é’¥")
    print("4. é‡æ–°è¿è¡Œç¨‹åº")
    print()
    sys.exit(1)
except ValueError as e:
    print("=" * 60)
    print("âŒ é…ç½®éªŒè¯å¤±è´¥")
    print("=" * 60)
    print()
    print(str(e))
    print()
    print("è¯·æ£€æŸ¥ llm_config.yml æ–‡ä»¶ä¸­çš„é…ç½®")
    print()
    sys.exit(1)
except Exception as e:
    print("=" * 60)
    print("âŒ åŠ è½½é…ç½®å¤±è´¥")
    print("=" * 60)
    print()
    print(f"é”™è¯¯: {e}")
    print()
    sys.exit(1)

from backend.llm_service import get_llm_service
from backend.animation_validator import validate_animation_data

# é…ç½®æ—¥å¿—
log_level = os.getenv('LOG_LEVEL', 'INFO')
log_format = os.getenv('LOG_FORMAT', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
log_file = os.getenv('LOG_FILE', '')

logging.basicConfig(
    level=getattr(logging, log_level),
    format=log_format,
    handlers=[
        logging.StreamHandler(),
        *([logging.FileHandler(log_file)] if log_file else [])
    ]
)
logger = logging.getLogger(__name__)

# Initialize Flask app
app = Flask(__name__)
CORS(app)

# Configuration
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'dev-secret-key-change-in-production')
app.config['JSON_AS_ASCII'] = False  # Support Chinese characters


@app.route('/')
def index():
    """Main page"""
    return render_template('index.html')


@app.route('/api/generate', methods=['POST'])
def generate_animation():
    """
    Generate animation from story description
    
    Request JSON:
        {
            "story": "Story description in natural language"
        }
    
    Response JSON:
        {
            "success": true,
            "data": { animation_data },
            "message": "Success message"
        }
    """
    try:
        # Get story from request
        data = request.get_json()
        
        if not data or 'story' not in data:
            return jsonify({
                'success': False,
                'message': 'Missing story parameter'
            }), 400
        
        story = data['story'].strip()
        
        if not story:
            return jsonify({
                'success': False,
                'message': 'Story cannot be empty'
            }), 400
        
        # Generate animation using LLM
        llm_service = get_llm_service()
        animation_data = llm_service.generate_animation(story)
        
        # Validate animation data
        try:
            validated_data = validate_animation_data(animation_data)
        except ValueError as ve:
            # If validation fails, return raw data with warning
            print(f"Validation warning: {str(ve)}")
            validated_data = animation_data
        
        return jsonify({
            'success': True,
            'data': validated_data,
            'message': 'Animation generated successfully'
        })
    
    except Exception as e:
        print(f"Error generating animation: {str(e)}")
        return jsonify({
            'success': False,
            'message': f'Error generating animation: {str(e)}'
        }), 500


@app.route('/api/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'provider': os.getenv('LLM_PROVIDER', 'openai')
    })


@app.errorhandler(404)
def not_found(error):
    """Handle 404 errors"""
    return jsonify({
        'success': False,
        'message': 'Endpoint not found'
    }), 404


@app.errorhandler(500)
def internal_error(error):
    """Handle 500 errors"""
    return jsonify({
        'success': False,
        'message': 'Internal server error'
    }), 500


if __name__ == '__main__':
    host = os.getenv('FLASK_HOST', '0.0.0.0')
    port = int(os.getenv('FLASK_PORT', 5000))
    debug = os.getenv('FLASK_DEBUG', 'True').lower() == 'true'
    
    print("=" * 60)
    print("ğŸ¬ AI Stick Figure Story Animator")
    print("=" * 60)
    print(f"ğŸŒ Server: http://{host}:{port}")
    
    provider = os.getenv('LLM_PROVIDER', 'openai')
    model_env_var = f"{provider.upper()}_MODEL"
    model = os.getenv(model_env_var, 'N/A')
    
    print(f"ğŸ¤– LLM Provider: {provider}")
    print(f"ğŸ¨ Model: {model}")
    print(f"ğŸ”§ Debug Mode: {debug}")
    print(f"ğŸ“Š Log Level: {log_level}")
    print("=" * 60)
    print()
    print("ğŸ“„ é…ç½®æ–‡ä»¶:")
    print("   - config.yml (ç³»ç»Ÿé…ç½®)")
    print("   - llm_config.yml (APIä»¤ç‰Œ)")
    print()
    print("è¯¦ç»†é…ç½®ï¼ˆæ•æ„Ÿä¿¡æ¯å·²éšè—ï¼‰:")
    print(config_loader.display())
    print()
    print("=" * 60)
    
    logger.info(f"Starting server on {host}:{port}")
    app.run(host=host, port=port, debug=debug)
