#!/usr/bin/env python3
"""
é…ç½®åŠ è½½å™¨ - ä» YAML é…ç½®æ–‡ä»¶åŠ è½½é…ç½®åˆ°ç¯å¢ƒå˜é‡

é‡‡ç”¨åŒé…ç½®æ–‡ä»¶è®¾è®¡:
- llm_config.yml: LLM API ä»¤ç‰Œï¼ˆæ•æ„Ÿä¿¡æ¯ï¼Œä¸æäº¤åˆ°Gitï¼‰
- config.yml: ç³»ç»Ÿé…ç½®ï¼ˆå¯æäº¤åˆ°Gitï¼‰

ä½¿ç”¨æ–¹æ³•:
    from backend.config_loader import load_config_to_env
    load_config_to_env()

Author: Your Name
License: MIT
"""
import os
import sys
import yaml
from pathlib import Path


class ConfigLoader:
    """é…ç½®åŠ è½½å™¨"""
    
    def __init__(self, config_file='config.yml', llm_config_file='llm_config.yml'):
        """
        åˆå§‹åŒ–é…ç½®åŠ è½½å™¨
        
        Args:
            config_file: ç³»ç»Ÿé…ç½®æ–‡ä»¶è·¯å¾„
            llm_config_file: LLMä»¤ç‰Œé…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_file = Path(config_file)
        self.llm_config_file = Path(llm_config_file)
        self.config = None
        self.llm_config = None
    
    def load(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        # åŠ è½½ç³»ç»Ÿé…ç½®
        if not self.config_file.exists():
            raise FileNotFoundError(
                f"ç³»ç»Ÿé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.config_file}\n"
                f"è¯¥æ–‡ä»¶åº”è¯¥å­˜åœ¨äºä»£ç åº“ä¸­"
            )
        
        # åŠ è½½LLMä»¤ç‰Œé…ç½®
        if not self.llm_config_file.exists():
            raise FileNotFoundError(
                f"LLMä»¤ç‰Œé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.llm_config_file}\n"
                f"è¯·å¤åˆ¶ llm_config.example.yml ä¸º llm_config.yml å¹¶å¡«å…¥APIå¯†é’¥"
            )
        
        try:
            # è¯»å–ç³»ç»Ÿé…ç½®
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
            
            if not self.config:
                raise ValueError("ç³»ç»Ÿé…ç½®æ–‡ä»¶ä¸ºç©º")
            
            # è¯»å–LLMä»¤ç‰Œé…ç½®
            with open(self.llm_config_file, 'r', encoding='utf-8') as f:
                self.llm_config = yaml.safe_load(f)
            
            if not self.llm_config:
                raise ValueError("LLMä»¤ç‰Œé…ç½®æ–‡ä»¶ä¸ºç©º")
            
            return self.config, self.llm_config
        
        except yaml.YAMLError as e:
            raise ValueError(f"YAMLè§£æé”™è¯¯: {e}")
        except Exception as e:
            raise Exception(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
    
    def to_env(self):
        """å°†é…ç½®è½¬æ¢ä¸ºç¯å¢ƒå˜é‡"""
        if not self.config or not self.llm_config:
            self.load()
        
        # LLMæä¾›å•†é…ç½®
        llm_system_config = self.config.get('llm', {})
        provider = llm_system_config.get('provider', 'openai')
        os.environ['LLM_PROVIDER'] = provider
        
        # OpenAIé…ç½®
        if 'openai' in llm_system_config:
            openai_system = llm_system_config['openai']
            openai_tokens = self.llm_config.get('openai', {})
            
            # APIå¯†é’¥æ¥è‡ª llm_config.yml
            os.environ['OPENAI_API_KEY'] = openai_tokens.get('api_key', '')
            
            # å…¶ä»–é…ç½®æ¥è‡ª config.yml
            os.environ['OPENAI_MODEL'] = openai_system.get('model', 'gpt-4-turbo-preview')
            os.environ['OPENAI_API_BASE'] = openai_system.get('api_base', '')
            os.environ['OPENAI_ORGANIZATION'] = openai_system.get('organization', '')
            os.environ['OPENAI_TIMEOUT'] = str(openai_system.get('timeout', 60))
            os.environ['OPENAI_MAX_RETRIES'] = str(openai_system.get('max_retries', 3))
            os.environ['OPENAI_TEMPERATURE'] = str(openai_system.get('temperature', 0.7))
        
        # Anthropicé…ç½®
        if 'anthropic' in llm_system_config:
            anthropic_system = llm_system_config['anthropic']
            anthropic_tokens = self.llm_config.get('anthropic', {})
            
            # APIå¯†é’¥æ¥è‡ª llm_config.yml
            os.environ['ANTHROPIC_API_KEY'] = anthropic_tokens.get('api_key', '')
            
            # å…¶ä»–é…ç½®æ¥è‡ª config.yml
            os.environ['ANTHROPIC_MODEL'] = anthropic_system.get('model', 'claude-3-sonnet-20240229')
            os.environ['ANTHROPIC_API_BASE'] = anthropic_system.get('api_base', '')
            os.environ['ANTHROPIC_TIMEOUT'] = str(anthropic_system.get('timeout', 60))
            os.environ['ANTHROPIC_MAX_RETRIES'] = str(anthropic_system.get('max_retries', 3))
            os.environ['ANTHROPIC_TEMPERATURE'] = str(anthropic_system.get('temperature', 0.7))
            os.environ['ANTHROPIC_MAX_TOKENS'] = str(anthropic_system.get('max_tokens', 4096))
        
        # PerfXCloudé…ç½®
        if 'perfxcloud' in llm_system_config:
            perfxcloud_system = llm_system_config['perfxcloud']
            perfxcloud_tokens = self.llm_config.get('perfxcloud', {})
            
            # APIå¯†é’¥æ¥è‡ª llm_config.yml
            os.environ['PERFXCLOUD_API_KEY'] = perfxcloud_tokens.get('api_key', '')
            
            # å…¶ä»–é…ç½®æ¥è‡ª config.yml
            os.environ['PERFXCLOUD_MODEL'] = perfxcloud_system.get('model', 'Qwen3-Next-80B-Instruct')
            os.environ['PERFXCLOUD_API_BASE'] = perfxcloud_system.get('api_base', '')
            os.environ['PERFXCLOUD_TIMEOUT'] = str(perfxcloud_system.get('timeout', 120))
            os.environ['PERFXCLOUD_MAX_RETRIES'] = str(perfxcloud_system.get('max_retries', 3))
            os.environ['PERFXCLOUD_TEMPERATURE'] = str(perfxcloud_system.get('temperature', 0.7))
            os.environ['PERFXCLOUD_MAX_TOKENS'] = str(perfxcloud_system.get('max_tokens', 4096))
            os.environ['PERFXCLOUD_MAX_CONTEXT_TOKENS'] = str(perfxcloud_system.get('max_context_tokens', 128000))
        
        # æœåŠ¡å™¨é…ç½®
        if 'server' in self.config:
            server_config = self.config['server']
            os.environ['FLASK_HOST'] = server_config.get('host', '0.0.0.0')
            os.environ['FLASK_PORT'] = str(server_config.get('port', 5000))
            os.environ['FLASK_DEBUG'] = str(server_config.get('debug', True))
            os.environ['SECRET_KEY'] = server_config.get('secret_key', 'dev-secret-key')
        
        # åŠ¨ç”»é…ç½®
        if 'animation' in self.config:
            animation_config = self.config['animation']
            if 'canvas' in animation_config:
                os.environ['CANVAS_WIDTH'] = str(animation_config['canvas'].get('width', 800))
                os.environ['CANVAS_HEIGHT'] = str(animation_config['canvas'].get('height', 600))
            
            if 'colors' in animation_config:
                os.environ['DEFAULT_COLORS'] = ','.join(animation_config['colors'])
            
            os.environ['MAX_SCENES'] = str(animation_config.get('max_scenes', 10))
            os.environ['MAX_CHARACTERS'] = str(animation_config.get('max_characters', 5))
            os.environ['MAX_FRAMES_PER_SCENE'] = str(animation_config.get('max_frames_per_scene', 20))
        
        # æ—¥å¿—é…ç½®
        if 'logging' in self.config:
            logging_config = self.config['logging']
            os.environ['LOG_LEVEL'] = logging_config.get('level', 'INFO')
            os.environ['LOG_FORMAT'] = logging_config.get('format', '%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            os.environ['LOG_FILE'] = logging_config.get('file', '')
    
    def validate(self):
        """éªŒè¯é…ç½®"""
        if not self.config or not self.llm_config:
            self.load()
        
        errors = []
        
        # éªŒè¯LLMé…ç½®
        llm_system_config = self.config.get('llm', {})
        provider = llm_system_config.get('provider')
        
        if not provider:
            errors.append("æœªæŒ‡å®šLLMæä¾›å•† (config.yml -> llm.provider)")
        elif provider not in ['openai', 'anthropic', 'perfxcloud', 'custom']:
            errors.append(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}")
        
        # éªŒè¯é€‰å®šæä¾›å•†çš„APIå¯†é’¥
        if provider == 'openai':
            api_key = self.llm_config.get('openai', {}).get('api_key', '')
            if not api_key or 'your_' in api_key:
                errors.append("æœªé…ç½®OpenAI APIå¯†é’¥ (llm_config.yml -> openai.api_key)")
        
        elif provider == 'anthropic':
            api_key = self.llm_config.get('anthropic', {}).get('api_key', '')
            if not api_key or 'your_' in api_key:
                errors.append("æœªé…ç½®Anthropic APIå¯†é’¥ (llm_config.yml -> anthropic.api_key)")
        
        elif provider == 'perfxcloud':
            api_key = self.llm_config.get('perfxcloud', {}).get('api_key', '')
            if not api_key or 'your_' in api_key:
                errors.append("æœªé…ç½®PerfXCloud APIå¯†é’¥ (llm_config.yml -> perfxcloud.api_key)")
        
        if errors:
            raise ValueError("é…ç½®éªŒè¯å¤±è´¥:\n" + "\n".join(f"  - {e}" for e in errors))
        
        return True
    
    def get(self, key_path, default=None, from_llm_config=False):
        """
        è·å–é…ç½®å€¼
        
        Args:
            key_path: é…ç½®è·¯å¾„ï¼Œå¦‚ 'llm.openai.model'
            default: é»˜è®¤å€¼
            from_llm_config: æ˜¯å¦ä»LLMé…ç½®è¯»å–
            
        Returns:
            é…ç½®å€¼
        """
        if not self.config or not self.llm_config:
            self.load()
        
        source = self.llm_config if from_llm_config else self.config
        keys = key_path.split('.')
        value = source
        
        for key in keys:
            if isinstance(value, dict):
                value = value.get(key)
                if value is None:
                    return default
            else:
                return default
        
        return value if value is not None else default
    
    def display(self):
        """æ˜¾ç¤ºå½“å‰é…ç½®ï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰"""
        if not self.config or not self.llm_config:
            self.load()
        
        def mask_sensitive(obj, path=''):
            """é€’å½’é®è”½æ•æ„Ÿä¿¡æ¯"""
            if isinstance(obj, dict):
                result = {}
                for key, value in obj.items():
                    current_path = f"{path}.{key}" if path else key
                    if 'key' in key.lower() or 'secret' in key.lower():
                        if value and len(str(value)) > 8:
                            result[key] = str(value)[:4] + '***' + str(value)[-4:]
                        else:
                            result[key] = '***'
                    else:
                        result[key] = mask_sensitive(value, current_path)
                return result
            elif isinstance(obj, list):
                return [mask_sensitive(item, path) for item in obj]
            else:
                return obj
        
        import json
        
        display_config = {
            'system_config': mask_sensitive(self.config),
            'llm_tokens': mask_sensitive(self.llm_config)
        }
        
        return json.dumps(display_config, indent=2, ensure_ascii=False)


def load_config_to_env(config_file='config.yml', llm_config_file='llm_config.yml'):
    """
    åŠ è½½é…ç½®åˆ°ç¯å¢ƒå˜é‡ï¼ˆä¾¿æ·å‡½æ•°ï¼‰
    
    Args:
        config_file: ç³»ç»Ÿé…ç½®æ–‡ä»¶è·¯å¾„
        llm_config_file: LLMä»¤ç‰Œé…ç½®æ–‡ä»¶è·¯å¾„
    """
    loader = ConfigLoader(config_file, llm_config_file)
    loader.load()
    loader.validate()
    loader.to_env()
    return loader


# å¯¼å‡º
__all__ = ['ConfigLoader', 'load_config_to_env']


if __name__ == '__main__':
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print("=" * 60)
    print("ğŸ”§ é…ç½®åŠ è½½å™¨æµ‹è¯•")
    print("=" * 60)
    print()
    
    try:
        loader = ConfigLoader()
        
        print("1ï¸âƒ£  åŠ è½½é…ç½®æ–‡ä»¶...")
        loader.load()
        print("   âœ… ç³»ç»Ÿé…ç½®: config.yml")
        print("   âœ… LLMä»¤ç‰Œ: llm_config.yml")
        print()
        
        print("2ï¸âƒ£  éªŒè¯é…ç½®...")
        loader.validate()
        print("   âœ… é…ç½®éªŒè¯é€šè¿‡")
        print()
        
        print("3ï¸âƒ£  è½¬æ¢ä¸ºç¯å¢ƒå˜é‡...")
        loader.to_env()
        print("   âœ… ç¯å¢ƒå˜é‡è®¾ç½®å®Œæˆ")
        print()
        
        print("4ï¸âƒ£  å½“å‰é…ç½®ï¼ˆæ•æ„Ÿä¿¡æ¯å·²é®è”½ï¼‰:")
        print(loader.display())
        print()
        
        print("=" * 60)
        print("âœ… é…ç½®åŠ è½½æµ‹è¯•å®Œæˆ")
        print("=" * 60)
        print()
        print("é…ç½®æ–‡ä»¶è¯´æ˜:")
        print("  - config.yml: ç³»ç»Ÿé…ç½®ï¼ˆå¯æäº¤åˆ°Gitï¼‰")
        print("  - llm_config.yml: APIä»¤ç‰Œï¼ˆä¸æäº¤åˆ°Gitï¼‰")
        
    except FileNotFoundError as e:
        print(f"âŒ {e}")
        sys.exit(1)
    except ValueError as e:
        print(f"âŒ {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
