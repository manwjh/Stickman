# ğŸ“‹ é…ç½®æŒ‡å—

## æ¦‚è¿°

æœ¬é¡¹ç›®é‡‡ç”¨**åŒé…ç½®æ–‡ä»¶**è®¾è®¡ï¼š

- `config.yml` - ç³»ç»Ÿé…ç½®ï¼ˆå¯æäº¤åˆ° Gitï¼‰
- `llm_config.yml` - API å¯†é’¥ï¼ˆä¸æäº¤åˆ° Gitï¼‰

## å¿«é€Ÿé…ç½®

### 1. å¤åˆ¶ç¤ºä¾‹é…ç½®

```bash
cp llm_config.example.yml llm_config.yml
```

### 2. å¡«å…¥ API å¯†é’¥

ç¼–è¾‘ `llm_config.yml`:

```yaml
openai:
  api_key: "sk-your-actual-key"

anthropic:
  api_key: "sk-ant-your-key"

perfxcloud:
  api_key: "sk-your-key"
```

### 3. é€‰æ‹© LLM æä¾›å•†

ç¼–è¾‘ `config.yml`:

```yaml
llm:
  provider: openai  # æˆ– anthropic, perfxcloud
```

## é…ç½®æ–‡ä»¶è¯´æ˜

### config.yml

**ç³»ç»Ÿé…ç½®æ–‡ä»¶** - å¯ä»¥æäº¤åˆ° Git

```yaml
# LLM æä¾›å•†
llm:
  provider: openai
  
  openai:
    model: "gpt-4-turbo-preview"
    api_base: ""
    temperature: 0.7
    max_tokens: 4096
  
  anthropic:
    model: "claude-3-sonnet-20240229"
    temperature: 0.7
    max_tokens: 4096
  
  perfxcloud:
    model: "Qwen3-Next-80B-Instruct"
    api_base: "https://deepseek.perfxlab.cn/v1"
    temperature: 0.7
    max_tokens: 4096

# æœåŠ¡å™¨é…ç½®
server:
  host: "0.0.0.0"
  port: 5001
  debug: true

# åŠ¨ç”»é…ç½®
animation:
  canvas:
    width: 800
    height: 600
  max_scenes: 10
  max_characters: 5

# æ—¥å¿—é…ç½®
logging:
  level: "INFO"
  file: ""
```

### llm_config.yml

**æ•æ„Ÿä¿¡æ¯æ–‡ä»¶** - ä¸æäº¤åˆ° Git

```yaml
openai:
  api_key: "sk-your-key"

anthropic:
  api_key: "sk-ant-your-key"

perfxcloud:
  api_key: "sk-your-key"
```

## LLM æä¾›å•†é…ç½®

### OpenAI

```yaml
# config.yml
llm:
  provider: openai
  openai:
    model: "gpt-4-turbo-preview"  # æˆ– gpt-3.5-turbo
    temperature: 0.7
    max_tokens: 4096

# llm_config.yml
openai:
  api_key: "sk-your-openai-key"
```

è·å–å¯†é’¥: https://platform.openai.com/api-keys

### Anthropic Claude

```yaml
# config.yml
llm:
  provider: anthropic
  anthropic:
    model: "claude-3-sonnet-20240229"
    temperature: 0.7
    max_tokens: 4096

# llm_config.yml
anthropic:
  api_key: "sk-ant-your-anthropic-key"
```

è·å–å¯†é’¥: https://console.anthropic.com/

### PerfXCloud

```yaml
# config.yml
llm:
  provider: perfxcloud
  perfxcloud:
    model: "Qwen3-Next-80B-Instruct"
    api_base: "https://deepseek.perfxlab.cn/v1"
    temperature: 0.7
    max_tokens: 4096

# llm_config.yml
perfxcloud:
  api_key: "sk-your-perfxcloud-key"
```

## å¸¸è§é…ç½®

### ä½¿ç”¨ä»£ç†

```yaml
llm:
  openai:
    api_base: "https://your-proxy.com/v1"
```

### æ›´æ”¹ç«¯å£

```yaml
server:
  port: 8080
```

### ç”Ÿäº§ç¯å¢ƒ

```yaml
server:
  debug: false
  secret_key: "your-strong-secret-key"

logging:
  level: "WARNING"
  file: "/var/log/stick_figure/app.log"
```

## æµ‹è¯•é…ç½®

```bash
python backend/config_loader.py
```

## å®‰å…¨å»ºè®®

1. âœ… æ°¸è¿œä¸è¦æäº¤ `llm_config.yml`
2. âœ… ä½¿ç”¨å¼ºå¯†é’¥ä½œä¸º `secret_key`
3. âœ… ç”Ÿäº§ç¯å¢ƒå…³é—­ `debug`
4. âœ… å®šæœŸè½®æ¢ API å¯†é’¥

## æ›´å¤šä¿¡æ¯

- [å¿«é€Ÿå¼€å§‹](GETTING_STARTED.md)
- [API æ–‡æ¡£](API.md)
- [å¼€å‘æ–‡æ¡£](DEVELOPMENT.md)
